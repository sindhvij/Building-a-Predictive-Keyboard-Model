# Building-a-Predictive-Keyboard-Model

## ðŸ“˜ Project Overview

This project involves building a **predictive keyboard model** that suggests the next word based on the previous text input. Such models are commonly used in messaging apps and virtual keyboards to improve typing efficiency and user experience.

---

## ðŸŽ¯ Objectives

- Train a deep learning model to predict the next word in a sentence
- Preprocess large-scale text datasets for training
- Evaluate model performance using accuracy and perplexity
- Experiment with different NLP architectures (RNN, LSTM, GRU, Transformer)

---

## ðŸ“¦ Key Features

- **Data Source**:The Adventures of Sherlock Holmes The Memoirs of Sherlock Holmes The Return of Sherlock Holmes His Last Bow The Case-Book of Sherlock Holmes
- **Tokenization**: Word-level or subword-level using `nltk` or `tokenizers`
- **Text Preprocessing**: Cleaning, padding, and encoding sequences
- **Model implemented**:
-1. N-Gram Language Model (Baseline)
-2. GRU (Gated Recurrent Unit) Model
-3. LSTM (Long Short-Term Memory) Model
-4. Transformer-based Model

- **Training**:
  - Implemented using PyTorch or TensorFlow
  - Cross-entropy loss function
  - Optimizer: Adam
- **Evaluation**:
  - Accuracy, Perplexity
  - Sample predictions

---

## ðŸ›  Tools & Libraries

| Task              | Tools/Libraries              |
|-------------------|------------------------------|
| Language          | Python 3                     |
| NLP               | nltk     |
| Deep Learning     | PyTorch / TensorFlow         |
| Visualization     | matplotlib, seaborn          |
| Dataset Handling  | pandas, NumPy                |

---



